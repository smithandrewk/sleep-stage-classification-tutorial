{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset,ConcatDataset,DataLoader,WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "colors = {\n",
    "    'Train': '#007AFF',  # Apple Blue\n",
    "    'Test': '#FF9500'    # Apple Orange\n",
    "}\n",
    "device = 'cuda'\n",
    "path_to_pt_ekyn = f'../pt_ekyn'\n",
    "\n",
    "def moving_average(data, window_size=10):\n",
    "    return np.convolve(data, np.ones(window_size), 'valid') / window_size\n",
    "\n",
    "def load_ekyn(id,condition,path_to_pt_ekyn=path_to_pt_ekyn):\n",
    "    X,y = torch.load(f'{path_to_pt_ekyn}/{id}_{condition}.pt',weights_only=False)\n",
    "    X = X.unsqueeze(1)\n",
    "    X = X[:,:,::10] # 500 Hz -> 50 Hz\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1-0', 'A1-1', 'A4-0', 'B1-0', 'B3-1', 'C1-0', 'C4-0', 'C4-1', 'D1-0', 'E1-0', 'E2-1', 'E4-0', 'E4-1', 'F1-0', 'F1-1', 'F5-1']\n",
      "A1-0\n",
      "A1-1\n",
      "A4-0\n",
      "B1-0\n",
      "B3-1\n",
      "C1-0\n",
      "C4-0\n",
      "C4-1\n",
      "D1-0\n",
      "E1-0\n",
      "E2-1\n",
      "E4-0\n",
      "E4-1\n",
      "F1-0\n",
      "F1-1\n",
      "F5-1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "(4) Normalize separately in training \n",
    "\"\"\"\n",
    "ids = sorted(set([recording_filename.split('_')[0] for recording_filename in os.listdir(path_to_pt_ekyn)]))\n",
    "print(ids)\n",
    "trains = []\n",
    "tests = []\n",
    "n_rats = 16\n",
    "\n",
    "for id in ids[:n_rats]:\n",
    "    print(id)\n",
    "    X,y = load_ekyn(id,'PF')\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,shuffle=True,stratify=y,random_state=0)\n",
    "    trains.append(X_train)\n",
    "    trains.append(y_train)\n",
    "    tests.append(X_test)\n",
    "    tests.append(y_test)\n",
    "\n",
    "trainloader = DataLoader(TensorDataset(*trains),batch_size=512,shuffle=True)\n",
    "testloader = DataLoader(TensorDataset(*tests),batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicNormCNNSleepStager(\n",
       "  (norms): ModuleList(\n",
       "    (0-15): 16 x SimpleNorm()\n",
       "  )\n",
       "  (c1): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=same)\n",
       "  (c2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  (c3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "  (mp): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (classifier): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class SimpleNorm(nn.Module):\n",
    "    def __init__(self,eps):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.tensor(1.0))\n",
    "        self.shift = nn.Parameter(torch.tensor(0.0))\n",
    "    def forward(self,x):\n",
    "        mean = x.flatten().mean()\n",
    "        std = x.flatten().std()\n",
    "        x = (x - mean) / (std + self.eps)\n",
    "        return x * self.scale + self.shift\n",
    "    \n",
    "class DynamicNormCNNSleepStager(nn.Module):\n",
    "    def __init__(self, n_rats, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.norms = nn.ModuleList([SimpleNorm(1e-5) for _ in range(n_rats)])\n",
    "\n",
    "        self.c1 = nn.Conv1d(in_channels=1,out_channels=64,kernel_size=7,padding='same')\n",
    "        self.c2 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=5,padding='same')\n",
    "        self.c3 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=3,padding='same')\n",
    "\n",
    "        self.mp = nn.MaxPool1d(kernel_size=2)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=64,out_features=32)\n",
    "        self.classifier = nn.Linear(in_features=32,out_features=3)\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([self.norms[i](x[i]) for i in range(len(x))])\n",
    "        \n",
    "        x = self.c1(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        x = relu(x)\n",
    "        x = self.mp(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = DynamicNormCNNSleepStager(n_rats)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 572/5000 [27:51<44:12:07, 35.94s/it]"
     ]
    }
   ],
   "source": [
    "trainlossi = []\n",
    "testlossi = []\n",
    "window_size = 10\n",
    "validation_frequency_epochs = 1\n",
    "best_dev_loss = torch.inf\n",
    "best_dev_loss_epoch = 0\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "n_validations = 0\n",
    "for epoch in tqdm(range(5000)):\n",
    "    for data in trainloader:\n",
    "        data = [d.to(device) for d in data]\n",
    "        Xi = data[::2]\n",
    "        yi = torch.cat(data[1::2])\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xi)\n",
    "        loss = criterion(logits,yi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainlossi.append(loss.item())\n",
    "\n",
    "    if epoch % validation_frequency_epochs == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            testlossi.append(torch.hstack([criterion(model([d.to(device) for d in data[::2]]),torch.cat([d.to(device) for d in data[1::2]]).to(device)).cpu() for data in testloader]).mean().item())\n",
    "\n",
    "        if testlossi[-1] < best_dev_loss:\n",
    "            best_dev_loss = testlossi[-1]\n",
    "            best_dev_loss_epoch = epoch\n",
    "\n",
    "        fig,axes = plt.subplots(nrows=1,ncols=1,figsize=(8,15),dpi=300)\n",
    "\n",
    "        # # Adjust figure background\n",
    "        # fig.patch.set_facecolor('black')\n",
    "\n",
    "        # # Adjust axes background\n",
    "        # axes.set_facecolor('black')\n",
    "\n",
    "        x_trainlossi = torch.linspace(0,(len(testlossi)-1)*validation_frequency_epochs,len(trainlossi))\n",
    "        x_testlossi = torch.linspace(0,(len(testlossi)-1)*validation_frequency_epochs,len(testlossi))\n",
    "\n",
    "        plt.plot(x_trainlossi,trainlossi, label='Train Loss', color=colors['Train'], alpha=0.4, linewidth=1.5)\n",
    "\n",
    "        if len(trainlossi) > window_size:\n",
    "            x_trainlossi_ma = torch.linspace(window_size-1,(len(testlossi)-1)*validation_frequency_epochs,len(trainlossi)-(window_size-1))\n",
    "            trainlossi_ma = moving_average(trainlossi, window_size)\n",
    "            plt.plot(x_trainlossi_ma, trainlossi_ma, label='Train Loss MA', color=colors['Train'], linestyle='--', linewidth=1.5)\n",
    "\n",
    "            plt.axvline(x=x_trainlossi_ma[trainlossi_ma.argmin()],color=colors['Train'], alpha=0.4)\n",
    "            min_trainlossi_ma = torch.tensor(trainlossi_ma).min()\n",
    "            plt.axhline(y=min_trainlossi_ma,color=colors['Train'], alpha=0.4)\n",
    "\n",
    "            # Add text on the right-hand side at the orange line value\n",
    "            plt.text(plt.xlim()[1] + .1, min_trainlossi_ma, f'{min_trainlossi_ma:.2f}', \n",
    "                    verticalalignment='center', horizontalalignment='left', color=colors['Train'], fontweight='bold')\n",
    "\n",
    "\n",
    "        plt.plot(x_testlossi,testlossi, label='Test Loss', color=colors['Test'], alpha=1, linewidth=1.5)\n",
    "\n",
    "        plt.axvline(x=x_testlossi[torch.tensor(testlossi).argmin()],color=colors['Test'], alpha=0.4)\n",
    "        min_testlossi = torch.tensor(testlossi).min()\n",
    "        plt.axhline(y=min_testlossi,color=colors['Test'], alpha=0.4)\n",
    "\n",
    "        # Add text on the right-hand side at the orange line value\n",
    "        plt.text(plt.xlim()[1] + .1, min_testlossi, f'{min_testlossi:.2f}', \n",
    "                verticalalignment='center', horizontalalignment='left', color=colors['Test'], fontweight='bold')\n",
    "        \n",
    "\n",
    "        plt.xlabel('epoch',fontweight='bold')\n",
    "        plt.ylabel('loss',fontweight='bold')\n",
    "\n",
    "        plt.ylim([0,1])\n",
    "        plt.savefig('loss.jpg',bbox_inches='tight')\n",
    "        plt.close()\n",
    "        model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.vstack([torch.vstack([model(Xi.to(device)).softmax(dim=1).argmax(dim=1).cpu(),yi.argmax(dim=1)]).T for Xi,yi in trainloader])\n",
    "y_pred = y[:,0]\n",
    "y_true = y[:,1]\n",
    "print(classification_report(y_true=y_true,y_pred=y_pred))\n",
    "\n",
    "y = torch.vstack([torch.vstack([model(Xi.to(device)).softmax(dim=1).argmax(dim=1).cpu(),yi.argmax(dim=1)]).T for Xi,yi in testloader])\n",
    "y_pred = y[:,0]\n",
    "y_true = y[:,1]\n",
    "print(classification_report(y_true=y_true,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sorted(set([recording_filename.split('_')[0] for recording_filename in os.listdir(path_to_pt_ekyn)]))\n",
    "\n",
    "X,y = torch.load(f'{path_to_pt_ekyn}/{ids[9]}_PF.pt',weights_only=False)\n",
    "X = X.unsqueeze(1)\n",
    "X = X[:,:,::10] # 500 Hz -> 50 Hz\n",
    "\n",
    "testloader = DataLoader(TensorDataset(X,y),batch_size=512,shuffle=True)\n",
    "\n",
    "Xi,yi = next(iter(testloader))\n",
    "print(Xi.shape,yi.shape,yi.argmax(dim=1).bincount())\n",
    "\n",
    "y = torch.vstack([torch.vstack([model(Xi.to(device)).softmax(dim=1).argmax(dim=1).cpu(),yi.argmax(dim=1)]).T for Xi,yi in testloader])\n",
    "y_pred = y[:,0]\n",
    "y_true = y[:,1]\n",
    "print(classification_report(y_true=y_true,y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
